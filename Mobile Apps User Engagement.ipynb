{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile App Usage Analysis\n",
    "\n",
    "Prepared by Amanda Morphew-Ulm  \n",
    "Last Edited: 2020-03-15  \n",
    "*An important note to the reader:\n",
    "This report was created as a guided project during the [Dataquest.io](https://app.dataquest.io/) course **Python for Data Science: Fundamentals**.*\n",
    "\n",
    "## Google Play and App Store\n",
    "\n",
    "This project explores data on existing Google Play and App Store mobile apps, including content rating, genre, downloads, and user ratings. As our company focuses on free-to-install apps that generate revenue via ads, our business model relies on user ad views and engagement. Therefore, our focus in analyzing this dataset is to understand what types of apps attract more users, so our developers can design our products for high levels of user engagement.\n",
    "\n",
    "There are over 2 million apps on each of the two stores our company develops for, and collecting data on all of them is not currently practical. We're using two publicly available data sets that comprise representative samples of the data we're looking for:\n",
    "- [A data set](https://www.kaggle.com/lava18/google-play-store-apps) containing data about approximately 10,000 Android apps from Google Play; the data was collected in August 2018.\n",
    "- [A data set](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps) containing data about approximately 7,000 iOS apps from the App Store; the data was collected in July 2017.\n",
    "\n",
    "First, we create a function to open and explore both data sets. This is a reusable set of code that lets us print easy-to-read rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters:\n",
    "#dataset - expected to be a list of lists; it should not include a header row\n",
    "#start and end - expected to be integers and represent the starting and ending indices of a slice from the data set\n",
    "#rows_and_columns - expected to be a Boolean and defaults to False\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice=dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') #\\n is a special character that adds a new empty line\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:',len(dataset))\n",
    "        print('Number of columns:',len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll open the two data set CSV files so we have each CSV file assigned to a Python variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opened_file=open('F:/Jupyter/datasets/AppleStore.csv',encoding='utf8')\n",
    "from csv import reader\n",
    "read_file=reader(opened_file)\n",
    "apple_apps_data=list(read_file)\n",
    "opened_file=open('F:/Jupyter/datasets/googleplaystore.csv',encoding='utf8')\n",
    "from csv import reader\n",
    "read_file=reader(opened_file)\n",
    "google_apps_data=list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our defined variables to access our data sets using:\n",
    "\n",
    "- apple_apps_data - iOS App Store data set\n",
    "- google_apps_data - Google Play Store data set\n",
    "\n",
    "Now we need to insert those variables into the function we defined above, along with a few adjustments. We'll start by printing the header row to see our column names, and then use our defined function to see the first five rows of data, the number of rows (excluding headers), and the number of columns:\n",
    "\n",
    "- Since the data has a header row, we use [1:] to exclude it\n",
    "- We want to look at just a few rows of data at first, to get an idea of what we have, so we'll use a start of 0 (the first row) and end of 5 (stop before the sixth row)\n",
    "- We need to change the rows_and_columns to True, since our data has both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "\n",
      "\n",
      "['420009108', 'Temple Run', '65921024', 'USD', '0.0', '1724546', '3842', '4.5', '4.0', '1.6.2', '9+', 'Games', '40', '5', '1', '1']\n",
      "\n",
      "\n",
      "['284035177', 'Pandora - Music & Radio', '130242560', 'USD', '0.0', '1126879', '3594', '4.0', '4.5', '8.4.1', '12+', 'Music', '37', '4', '1', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "print(apple_apps_data[0])\n",
    "print('\\n') #Add an empty line for readability\n",
    "explore_data(apple_apps_data[1:],0,5,rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "['Pixel Draw - Number Art Coloring Book', 'ART_AND_DESIGN', '4.3', '967', '2.8M', '100,000+', 'Free', '0', 'Everyone', 'Art & Design;Creativity', 'June 20, 2018', '1.1', '4.4 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "print(google_apps_data[0])\n",
    "print('\\n') #Add an empty line for readability\n",
    "explore_data(google_apps_data[1:],0,5,rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Before we begin analysis, we need to make sure the data is accurate. In other words, we need to detect inaccurate data, as well as duplicate data, and remove it from our data sets.\n",
    "\n",
    "Our company only produces free-to-install apps that are directed toward an English-speaking audience, so it makes sense to limit our data set to those parameters as well.\n",
    "\n",
    "### Inaccurate Data\n",
    "\n",
    "Since these data sets have been used extensively by other people completing similar analyses, we can check on the discussion boards where we downloaded the data sets.\n",
    "\n",
    "The [App Store discussion board](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/discussion) doesn't seem to indicate any data errors that other users have found.\n",
    "\n",
    "In the discussion board for the Google Play Store data set, we see a few reports of incorrect data:\n",
    "\n",
    "- [Wrong entry for Life Made WI-Fi Touchscreen Photo Frame](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) - I found that this row in our data set is index 10473; the poster most likely removed their header row and then noted the index\n",
    "- [Wrong Type value for Command & Conquer: Rivals](https://www.kaggle.com/lava18/google-play-store-apps/discussion/101414) - Checking the comments, we see that the index of this row is most likely 9149, as we have not removed any data from our data set at this point\n",
    "\n",
    "While we could search the Play Store and correct these values, we have a large enough sample that it makes more sense to delete these two rows. We will delete these two rows, lower row first (deleting from top down would change the index of the second row we want to delete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "Columns in this row: 12\n",
      "\n",
      "\n",
      "['Command & Conquer: Rivals', 'FAMILY', 'NaN', '0', 'Varies with device', '0', 'NaN', '0', 'Everyone 10+', 'Strategy', 'June 28, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "print(google_apps_data[10473])\n",
    "print('Columns in this row: ' + str(len(google_apps_data[10473])))\n",
    "print('\\n')\n",
    "print(google_apps_data[9149])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10473 removed.\n",
      "Row 9149 removed.\n"
     ]
    }
   ],
   "source": [
    "#Do not re-run this block without running entire notebook\n",
    "del google_apps_data[10473]\n",
    "print('Row 10473 removed.')\n",
    "del google_apps_data[9149]\n",
    "print('Row 9149 removed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Data\n",
    "\n",
    "While checking the discussion board for mentions of inaccurate data, we also see some users mention that duplicates occur in the Google Play Store data set. We will use the app name as the value to check for duplicates, using the below loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate apps: 1181\n",
      "\n",
      "\n",
      "Examples of duplicate apps: ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack', 'FreshBooks Classic', 'Insightly CRM', 'QuickBooks Accounting: Invoicing & Expenses', 'HipChat - Chat Built for Teams', 'Xero Accounting Software']\n"
     ]
    }
   ],
   "source": [
    "#Create empty lists into which we can separate the unique values from the repeated values\n",
    "duplicate_apps=[]\n",
    "unique_apps=[]\n",
    "#Loop through the Google Play data, minus the header row\n",
    "for app in google_apps_data[1:]:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[0]\n",
    "    #Check to see if we've already listed this app in the unique_apps list\n",
    "    if name in unique_apps:\n",
    "        #If we have, put this name in the duplicate_apps list instead\n",
    "        duplicate_apps.append(name)\n",
    "    else:\n",
    "        #If this app isn't listed yet in unique_apps, add it to that list instead\n",
    "        unique_apps.append(name)\n",
    "#View our results\n",
    "print('Number of duplicate apps:', len(duplicate_apps))\n",
    "print('\\n')\n",
    "print('Examples of duplicate apps:', duplicate_apps[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the names of our duplicate apps identified, how should we remove the extras?\n",
    "\n",
    "- If we choose a random one to keep, it may not contain the most recent data for that app\n",
    "- We could keep the highest version number; however, some rows say 'Varies with device'\n",
    "- The Installs column is written as interval strings, such as '1,000,000,000+', rather than integer values\n",
    "\n",
    "With those things in mind, our most likely candidate for identifying the most recent row for a duplicated app is going to be the Reviews column, which is stored here as specific integers and should only increase or stay the same as time passes.\n",
    "\n",
    "To remove the duplicates, we will:\n",
    "\n",
    "- Create a dictionary with unique app names as keys and their corresponding values are the highest number of reviews of that app\n",
    "- Use this information to create a new data set, which will have only one entry per app - the entry with the highest number of reviews from our original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9658\n"
     ]
    }
   ],
   "source": [
    "#We start by creating an empty dictionary\n",
    "reviews_max={}\n",
    "#Loop through the Google Play data, minus the header row\n",
    "for app in google_apps_data[1:]:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[0]\n",
    "    #Convert the number of reviews to a float and assign it to a variable\n",
    "    n_reviews=float(app[3])\n",
    "    #Check if name is already a key in reviews_max AND current n_reviews is larger than existing value\n",
    "    if name in reviews_max and reviews_max[name]<n_reviews:\n",
    "        #If yes, we update that existing value\n",
    "        reviews_max[name]=n_reviews\n",
    "    #Add name to reviews_max dictionary only if it's not already there\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name]=n_reviews\n",
    "    #If neither of the above are true, we don't want to update it, so no \"else\" here\n",
    "#We expect a length of 9658 after removing duplicates; let's test this:\n",
    "print(len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dictionary holding the highest number of reviews for each app, we can use this to scrub our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9658\n"
     ]
    }
   ],
   "source": [
    "#This will become our newly cleaned data set\n",
    "google_clean=[]\n",
    "#This will just store app names\n",
    "already_added=[]\n",
    "#Loop through the Google Play data, minus the header row\n",
    "for app in google_apps_data[1:]:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[0]\n",
    "    #Convert the number of reviews to a float and assign it to a variable\n",
    "    n_reviews=float(app[3])\n",
    "    #If this row is the one with the highest number of reviews\n",
    "    #We also need the second condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry\n",
    "    if n_reviews==reviews_max[name] and name not in already_added:\n",
    "        google_clean.append(app)\n",
    "        already_added.append(name)\n",
    "#Let's check the length to see if this went as planned; it should equal 9658\n",
    "print(len(google_clean))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a variable, google_clean, which contains our cleaned list of Google Play Store app data.\n",
    "\n",
    "As mentioned above, the iOS App Store discussion board does not mention any data errors or duplicates found by other users. However, we can quickly run our code again through the App Store data set to check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate apps: 2\n",
      "\n",
      "\n",
      "Examples of duplicate apps: ['Mannequin Challenge', 'VR Roller Coaster']\n"
     ]
    }
   ],
   "source": [
    "#Create empty lists into which we can separate the unique values from the repeated values\n",
    "duplicate_ios_apps=[]\n",
    "unique_ios_apps=[]\n",
    "#Loop through the iOS store data, minus the header row\n",
    "for app in apple_apps_data[1:]:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[1]\n",
    "    #Check to see if we've already listed this app in the unique_apps list\n",
    "    if name in unique_ios_apps:\n",
    "        #If we have, put this name in the duplicate_apps list instead\n",
    "        duplicate_ios_apps.append(name)\n",
    "    else:\n",
    "        #If this app isn't listed yet in unique_apps, add it to that list instead\n",
    "        unique_ios_apps.append(name)\n",
    "#View our results\n",
    "print('Number of duplicate apps:', len(duplicate_ios_apps))\n",
    "print('\\n')\n",
    "print('Examples of duplicate apps:', duplicate_ios_apps[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do find two duplicate app names for the Apple store data, let's run through the same process as we did with the Google apps data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7195\n"
     ]
    }
   ],
   "source": [
    "#Lets reset and reuse our reviews dictionary\n",
    "reviews_max={}\n",
    "#Loop through the Apple data, minus the header row\n",
    "for app in apple_apps_data[1:]:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[1]\n",
    "    #Convert the number of reviews to a float and assign it to a variable\n",
    "    n_reviews=float(app[5])\n",
    "    #Check if name is already a key in reviews_max AND current n_reviews is larger than existing value\n",
    "    if name in reviews_max and reviews_max[name]<n_reviews:\n",
    "        #If yes, we update that existing value\n",
    "        reviews_max[name]=n_reviews\n",
    "    #Add name to reviews_max dictionary only if it's not already there\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name]=n_reviews\n",
    "    #If neither of the above are true, we don't want to update it, so no \"else\" here\n",
    "#We expect a length of 7195 after removing duplicates; let's test this:\n",
    "print(len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did for the Google data, we can use our reviews_max dictionary to scrub our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7195\n"
     ]
    }
   ],
   "source": [
    "#This will become our newly cleaned data set\n",
    "apple_clean=[]\n",
    "#We'll reset and reuse this list that will just store app names\n",
    "already_added=[]\n",
    "#Loop through the Apple data, minus the header row\n",
    "for app in apple_apps_data[1:]:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[1]\n",
    "    #Convert the number of reviews to a float and assign it to a variable\n",
    "    n_reviews=float(app[5])\n",
    "    #If this row is the one with the highest number of reviews\n",
    "    #We also need the second condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry\n",
    "    if n_reviews==reviews_max[name] and name not in already_added:\n",
    "        apple_clean.append(app)\n",
    "        already_added.append(name)\n",
    "#Let's check the length to see if this went as planned; it should equal 7195\n",
    "print(len(apple_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Targeting\n",
    "\n",
    "*This section on language is taken verbatim from the Dataquest.io course, as their explanation is perfect and better than anything I tried to write!*\n",
    "\n",
    "Our analysis is geared toward an English-speaking audience as that is the only language for which our company develops apps. One way to go about this is to remove each app with a name containing a symbol that is not commonly used in English text ‚Äî English text usually includes letters from the English alphabet, numbers composed of digits from 0 to 9, punctuation marks (., !, ?, ;), and other symbols (+, *, /).\n",
    "\n",
    "Behind the scenes, each character we use in a string has a corresponding number associated with it. For instance, the corresponding number for character 'a' is 97, character 'A' is 65, and character 'Áà±' is 29,233. The numbers corresponding to the characters we commonly use in an English text are all in the range 0 to 127, according to the ASCII (American Standard Code for Information Interchange) system. Based on this number range, we can build a function that detects whether a character belongs to the set of common English characters or not. If the number is equal to or less than 127, then the character belongs to the set of common English characters.\n",
    "\n",
    "We can get the corresponding number of each character using the ord() built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "29233\n"
     ]
    }
   ],
   "source": [
    "print(ord('A'))\n",
    "print(ord('Áà±'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we can check the parts of an app name's string for the numbers, and exclude apps that have numbers higher than 127.\n",
    "\n",
    "Python allows us to index and iterate on strings much like lists, which allows us to extract individual characters of a string and run them through a loop to check their number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We enter the app name we want to check as name_string\n",
    "def english_check(name_string):\n",
    "    for single in name_string: #This will loop through each character in that name\n",
    "        if ord(single)>127:\n",
    "            return False\n",
    "            #If we find a non-English character, the function stops at this point\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return False if the app name contains non-English characters, and True if it does not.  \n",
    "Let's test it with a few individual app names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "is_english=english_check('Instagram')\n",
    "print(is_english)\n",
    "is_english=english_check('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠')\n",
    "print(is_english)\n",
    "is_english=english_check('Docs To Go‚Ñ¢ Free Office Suite')\n",
    "print(is_english)\n",
    "is_english=english_check('Instachat üòú')\n",
    "print(is_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that 'Docs To Go' and 'Instachat' are incorrectly flagged as non-English, presumably because of the ‚Ñ¢ and üòú characters, respectively. We can see why here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8482\n",
      "128540\n"
     ]
    }
   ],
   "source": [
    "print(ord('‚Ñ¢'))\n",
    "print(ord('üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the function used above will inadvertantly lose apps that we meant to keep in our data set. We can minimize this effect if we only remove an app with more than three non-English characters; in other words, a given app can have up to three emoji or other special characters and still be retained. This isn't a perfect solution, but it should be effective enough for our purposes here. Let's redefine our function and include this change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#We begin as before - enter the app name we want to check as name_string\n",
    "def english_check(name_string):\n",
    "    #Start an empty list to hold identified non-English characters\n",
    "    non_english_count=[]\n",
    "    for single in name_string: #This will loop through each character in that name\n",
    "        if ord(single)>127:\n",
    "            non_english_count.append(single) #Add each non-English character to our list\n",
    "    if len(non_english_count)>3:\n",
    "        return False\n",
    "        #If we have more than 3 characters flagged as non-English, the function stops here\n",
    "    return True            \n",
    "#Let's test our app names again with the edited function\n",
    "is_english=english_check('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠')\n",
    "print(is_english)\n",
    "is_english=english_check('Docs To Go‚Ñ¢ Free Office Suite')\n",
    "print(is_english)\n",
    "is_english=english_check('Instachat üòú')\n",
    "print(is_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our english_check function defined, we can run it on our duplicate-scrubbed data sets - google_clean and apple_clean - and generate new lists of those apps identified as English.\n",
    "\n",
    "It's important to remember at this point that apple_clean and google_clean no longer have header rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Google Apps:\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 9613\n",
      "Number of columns: 13\n",
      "\n",
      "\n",
      "Non-English Google Apps:\n",
      "['Flame - ÿØÿ±ÿ® ÿπŸÇŸÑŸÉ ŸäŸàŸÖŸäÿß', 'EDUCATION', '4.6', '56065', '37M', '1,000,000+', 'Free', '0', 'Everyone', 'Education', 'July 26, 2018', '3.3', '4.1 and up']\n",
      "\n",
      "\n",
      "Number of rows: 45\n",
      "Number of columns: 13\n",
      "\n",
      "\n",
      "Expected Total Apps: 9658\n",
      "Actual Total Apps: 9658\n"
     ]
    }
   ],
   "source": [
    "#Create our new list that will contain English Google app data only\n",
    "google_english=[]\n",
    "#Create a list to hold non-English app data so we can check our work\n",
    "google_non_english=[]\n",
    "#Loop through the cleaned Google play data\n",
    "for app in google_clean:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[0]\n",
    "    #If that name is decided by our english_check function to be an English language app, add it to our new list\n",
    "    if english_check(name):\n",
    "        google_english.append(app)\n",
    "    else:\n",
    "        google_non_english.append(app)\n",
    "#Lets use our explore_data function to check our work; the two lengths should add up to 9658\n",
    "print('English Google Apps:')\n",
    "explore_data(google_english,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Non-English Google Apps:')\n",
    "explore_data(google_non_english,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Expected Total Apps: 9658')\n",
    "print('Actual Total Apps: '+str(len(google_english)+len(google_non_english)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our sample rows, we can see that our language-based list separation appears successful, and that the lengths of the English and non-English lists add up to the expected number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Apple Apps:\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 6181\n",
      "Number of columns: 16\n",
      "\n",
      "\n",
      "Non-English Apple Apps:\n",
      "['445375097', 'Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠', '224617472', 'USD', '0.0', '14844', '0', '4.0', '0.0', '6.3.3', '17+', 'Entertainment', '38', '5', '3', '1']\n",
      "\n",
      "\n",
      "Number of rows: 1014\n",
      "Number of columns: 16\n",
      "\n",
      "\n",
      "Expected Total Apps: 7195\n",
      "Actual Total Apps: 7195\n"
     ]
    }
   ],
   "source": [
    "#Create our new list that will contain English Apple app data only\n",
    "apple_english=[]\n",
    "#Create a list to hold non-English app data so we can check our work\n",
    "apple_non_english=[]\n",
    "#Loop through the cleaned Apple data\n",
    "for app in apple_clean:\n",
    "    #Assign this app's name to a 'name' variable\n",
    "    name=app[1]\n",
    "    #If that name is decided by our english_check function to be an English language app, add it to our new list\n",
    "    if english_check(name):\n",
    "        apple_english.append(app)\n",
    "    else:\n",
    "        apple_non_english.append(app)\n",
    "#Lets check our work again; the two lengths should add up to 7195\n",
    "print('English Apple Apps:')\n",
    "explore_data(apple_english,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Non-English Apple Apps:')\n",
    "explore_data(apple_non_english,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Expected Total Apps: 7195')\n",
    "print('Actual Total Apps: '+str(len(apple_english)+len(apple_non_english)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw with the Google sample before, these samples and list lengths are in line with what we expect to see.\n",
    "\n",
    "We now have two lists:\n",
    "\n",
    "- google_english, a list of 9613 English language Google Play store apps\n",
    "- apple_english, a list of 6181 English language Apple App Store apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free and Non-Free Apps\n",
    "Our company only builds apps that are free to install, so as we did with language, it makes sense to isolate the free apps in our data sets. This will make our data sets as similar as possible to the products that our company produces.\n",
    "\n",
    "From our previous exploration of the data sets, we know that the price column for Apple apps contains string '0.0' for free apps, while the Google apps price column contains string '0' for free apps.\n",
    "\n",
    "As we did in our language-based list division, we'll check our resulting lists for appropriate rows and lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free English Google Apps:\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 8863\n",
      "Number of columns: 13\n",
      "\n",
      "\n",
      "Paid English Google Apps:\n",
      "['TurboScan: scan documents and receipts in PDF', 'BUSINESS', '4.7', '11442', '6.8M', '100,000+', 'Paid', '$4.99', 'Everyone', 'Business', 'March 25, 2018', '1.5.2', '4.0 and up']\n",
      "\n",
      "\n",
      "Number of rows: 750\n",
      "Number of columns: 13\n",
      "\n",
      "\n",
      "Expected Total Apps: 9613\n",
      "Actual Total Apps: 9613\n"
     ]
    }
   ],
   "source": [
    "#Create a list that will hold our free Google apps\n",
    "google_english_free=[]\n",
    "#Create a list to hold paid apps to check our work\n",
    "google_english_paid=[]\n",
    "for app in google_english:\n",
    "    if app[7]=='0':\n",
    "        google_english_free.append(app)\n",
    "    else:\n",
    "        google_english_paid.append(app)\n",
    "#Lets use our explore_data function to check our work; the two lengths should add up to 9613\n",
    "print('Free English Google Apps:')\n",
    "explore_data(google_english_free,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Paid English Google Apps:')\n",
    "explore_data(google_english_paid,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Expected Total Apps: 9613')\n",
    "print('Actual Total Apps: '+str(len(google_english_free)+len(google_english_paid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free English Apple Apps:\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 3220\n",
      "Number of columns: 16\n",
      "\n",
      "\n",
      "Paid English Apple Apps:\n",
      "['362949845', 'Fruit Ninja Classic', '104590336', 'USD', '1.99', '698516', '132', '4.5', '4.0', '2.3.9', '4+', 'Games', '38', '5', '13', '1']\n",
      "\n",
      "\n",
      "Number of rows: 2961\n",
      "Number of columns: 16\n",
      "\n",
      "\n",
      "Expected Total Apps: 6181\n",
      "Actual Total Apps: 6181\n"
     ]
    }
   ],
   "source": [
    "#Create a list that will hold our free Apple apps\n",
    "apple_english_free=[]\n",
    "#Create a list to hold paid apps to check our work\n",
    "apple_english_paid=[]\n",
    "for app in apple_english:\n",
    "    if app[4]=='0.0':\n",
    "        apple_english_free.append(app)\n",
    "    else:\n",
    "        apple_english_paid.append(app)\n",
    "#Lets use our explore_data function to check our work; the two lengths should add up to 6181\n",
    "print('Free English Apple Apps:')\n",
    "explore_data(apple_english_free,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Paid English Apple Apps:')\n",
    "explore_data(apple_english_paid,0,1,rows_and_columns=True)\n",
    "print('\\n')\n",
    "print('Expected Total Apps: 6181')\n",
    "print('Actual Total Apps: '+str(len(apple_english_free)+len(apple_english_paid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both lists of apps isolated down to only the free-to-install app rows, we're ready to move on from cleaning the data into analyzing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
